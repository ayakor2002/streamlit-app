# Syst√®me Int√©gr√© Streamlit avec Gestion Avanc√©e de l'Historique
# Installation: pip install streamlit pandas numpy plotly scikit-learn pulp openpyxl

import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import pickle 
import os
from datetime import datetime, timedelta
import base64
from io import BytesIO

# Imports pour ML et optimisation
from sklearn.model_selection import train_test_split, GridSearchCV, TimeSeriesSplit
from sklearn.preprocessing import StandardScaler
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.tree import DecisionTreeRegressor
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
from sklearn.neural_network import MLPRegressor
from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error
import pulp as plp
from typing import Dict, List, Tuple, Any
import warnings
warnings.filterwarnings('ignore')

# =====================================================================
# CONFIGURATION STREAMLIT
# =====================================================================

st.set_page_config(
    page_title="Syst√®me Int√©gr√© avec Historique",
    page_icon="üè≠",
    layout="wide",
    initial_sidebar_state="expanded"
)

# CSS personnalis√©
st.markdown("""
<style>
    .main-header {
        background: linear-gradient(90deg, #1f4e79, #2e86ab);
        padding: 1rem;
        border-radius: 10px;
        margin-bottom: 2rem;
        color: white;
        text-align: center;
    }
    .metric-card {
        background: #f0f2f6;
        padding: 1rem;
        border-radius: 10px;
        border-left: 4px solid #1f4e79;
        margin: 0.5rem 0;
    }
    .success-box {
        background: #d4edda;
        border: 1px solid #c3e6cb;
        border-radius: 5px;
        padding: 10px;
        margin: 10px 0;
    }
    .warning-box {
        background: #fff3cd;
        border: 1px solid #ffeaa7;
        border-radius: 5px;
        padding: 10px;
        margin: 10px 0;
    }
    .error-box {
        background: #f8d7da;
        border: 1px solid #f5c6cb;
        border-radius: 5px;
        padding: 10px;
        margin: 10px 0;
    }
    .history-card {
        background: #e8f5e8;
        border: 1px solid #c3e6cb;
        border-radius: 8px;
        padding: 15px;
        margin: 10px 0;
    }
</style>
""", unsafe_allow_html=True)

# =====================================================================
# CLASSES AM√âLIOR√âES AVEC HISTORIQUE
# =====================================================================

class EnhancedStreamlitDefectPredictor:
    """Pr√©dicteur am√©lior√© avec gestion de l'historique pour Streamlit"""
    
    def __init__(self):
        self.models = {}
        self.transformers = {}
        self.best_model_names = {}
        self.feature_importances = {}
        self.original_data = None
        self.postes = []
        self.jour_col = None
        self.volume_col = None
        self.predictions_history = []
        self.poste_weights = {}
        self.historical_accuracy = {}
        self.trend_weights = {}
        self.load_history()
    
    def load_history(self):
        """Charge l'historique depuis le state Streamlit"""
        if 'predictions_history' in st.session_state:
            self.predictions_history = st.session_state.predictions_history
        else:
            st.session_state.predictions_history = []
            self.predictions_history = []
    
    def save_history(self):
        """Sauvegarde l'historique dans le state Streamlit"""
        st.session_state.predictions_history = self.predictions_history
    
    def add_new_demand_prediction(self, jour, volume, actual_defects=None, method='moyenne_ponderee'):
        """Ajoute une nouvelle demande et fait une pr√©diction avec historique"""
        
        # 1. Pr√©diction ML standard
        ml_prediction = self._make_ml_prediction(jour, volume)
        
        # 2. Ajustement avec historique
        adjusted_prediction = self._adjust_with_historical_trend(ml_prediction, jour, volume)
        
        # 3. Calcul du taux final
        final_rework_rate = self._calculate_final_rework_rate(adjusted_prediction, jour, volume, method)
        
        # 4. Cr√©ation de l'enregistrement
        prediction_record = {
            'timestamp': datetime.now(),
            'jour': jour,
            'volume': volume,
            'method': method,
            'ml_prediction': ml_prediction,
            'adjusted_prediction': adjusted_prediction,
            'final_rework_rate': final_rework_rate,
            'actual_defects': actual_defects,
            'accuracy': None
        }
        
        # 5. Validation si d√©fauts r√©els fournis
        if actual_defects:
            accuracy = self._calculate_accuracy(adjusted_prediction, actual_defects, volume)
            prediction_record['accuracy'] = accuracy
            self._update_model_performance(accuracy, jour)
        
        # 6. Ajout √† l'historique
        self.predictions_history.append(prediction_record)
        self.save_history()
        
        return prediction_record
    
    def _make_ml_prediction(self, jour, volume):
        """Pr√©diction ML standard"""
        if not self.models:
            raise ValueError("Les mod√®les doivent √™tre entra√Æn√©s!")
        
        # Pr√©paration des donn√©es
        new_data = pd.DataFrame({
            self.volume_col: [volume],
            'jour_numerique': [jour]
        })
        X_new = new_data[[self.volume_col, 'jour_numerique']]
        
        # Pr√©dictions par poste
        predictions_postes = {}
        for poste, model in self.models.items():
            predictions_postes[poste] = max(0, model.predict(X_new)[0])
        
        # Pr√©dictions cha√Æne
        predictions_chaine = {
            'max': max(predictions_postes.values()) if predictions_postes else 0,
            'moyenne': np.mean(list(predictions_postes.values())) if predictions_postes else 0,
            'moyenne_ponderee': self.calculate_weighted_average(predictions_postes),
            'somme': sum(predictions_postes.values()) if predictions_postes else 0
        }
        
        # Taux de rework
        taux_rework_postes = {poste: (defauts / volume) * 100 
                             for poste, defauts in predictions_postes.items()}
        
        taux_rework_chaine = {method: (defauts / volume) * 100 
                             for method, defauts in predictions_chaine.items()}
        
        return {
            'predictions_postes': predictions_postes,
            'predictions_chaine': predictions_chaine,
            'taux_rework_postes': taux_rework_postes,
            'taux_rework_chaine': taux_rework_chaine
        }
    
    def _adjust_with_historical_trend(self, ml_prediction, jour, volume):
        """Ajuste avec les tendances historiques"""
        if len(self.predictions_history) < 3:
            return ml_prediction
        
        # Analyser les tendances r√©centes
        recent_predictions = [p for p in self.predictions_history[-10:] 
                            if p.get('accuracy') is not None]
        
        if not recent_predictions:
            return ml_prediction
        
        # Calculer le facteur de correction
        correction_factor = self._calculate_correction_factor(recent_predictions, jour)
        
        # Appliquer la correction
        adjusted_prediction = ml_prediction.copy()
        for method in adjusted_prediction['taux_rework_chaine']:
            original_rate = adjusted_prediction['taux_rework_chaine'][method]
            adjusted_rate = original_rate * correction_factor
            adjusted_prediction['taux_rework_chaine'][method] = max(0.1, min(30, adjusted_rate))
        
        return adjusted_prediction
    
    def _calculate_correction_factor(self, recent_predictions, jour):
        """Calcule le facteur de correction bas√© sur l'historique"""
        jour_errors = []
        all_errors = []
        
        for pred in recent_predictions:
            accuracy = pred.get('accuracy', 0)
            error_rate = max(0, (100 - accuracy) / 100)
            all_errors.append(error_rate)
            
            if pred['jour'] == jour:
                jour_errors.append(error_rate)
        
        if jour_errors:
            avg_error = np.mean(jour_errors)
            correction = 1.0 + (avg_error * 0.3)  # Correction mod√©r√©e
        elif all_errors:
            avg_error = np.mean(all_errors)
            correction = 1.0 + (avg_error * 0.2)  # Correction plus l√©g√®re
        else:
            correction = 1.0
        
        return max(0.7, min(1.5, correction))  # Borner la correction
    
    def _calculate_final_rework_rate(self, adjusted_prediction, jour, volume, method):
        """Calcule le taux final pour la planification"""
        base_rate = adjusted_prediction['taux_rework_chaine'][method]
        
        # Facteurs d'ajustement
        volume_factor = 0.98 if volume > 1500 else (1.02 if volume < 800 else 1.0)
        jour_factor = 1.08 if jour in [6, 7] else 1.0
        
        final_rate = base_rate * volume_factor * jour_factor
        return max(0.5, min(25, final_rate))
    
    def _calculate_accuracy(self, prediction, actual_defects, volume):
        """Calcule la pr√©cision de la pr√©diction"""
        predicted_total = sum(prediction['predictions_postes'].values())
        actual_total = sum(actual_defects.values())
        
        if actual_total == 0 and predicted_total == 0:
            return 100.0
        elif actual_total == 0:
            return max(0, 100 - (predicted_total / volume * 100))
        
        relative_error = abs(predicted_total - actual_total) / actual_total
        return max(0, 100 - (relative_error * 100))
    
    def _update_model_performance(self, accuracy, jour):
        """Met √† jour les performances des mod√®les"""
        if jour not in self.historical_accuracy:
            self.historical_accuracy[jour] = []
        
        self.historical_accuracy[jour].append(accuracy)
        if len(self.historical_accuracy[jour]) > 15:
            self.historical_accuracy[jour] = self.historical_accuracy[jour][-15:]
    
    def get_historical_statistics(self):
        """Retourne les statistiques de l'historique"""
        if not self.predictions_history:
            return None
        
        # Statistiques g√©n√©rales
        total_predictions = len(self.predictions_history)
        predictions_with_validation = [p for p in self.predictions_history 
                                     if p.get('accuracy') is not None]
        
        stats = {
            'total_predictions': total_predictions,
            'validated_predictions': len(predictions_with_validation),
            'recent_trend': self._get_recent_trend()
        }
        
        # Statistiques de pr√©cision
        if predictions_with_validation:
            accuracies = [p['accuracy'] for p in predictions_with_validation]
            stats.update({
                'avg_accuracy': np.mean(accuracies),
                'min_accuracy': np.min(accuracies),
                'max_accuracy': np.max(accuracies),
                'std_accuracy': np.std(accuracies)
            })
        
        # Statistiques par jour
        stats['by_day'] = {}
        for jour in range(1, 8):
            day_preds = [p for p in predictions_with_validation if p['jour'] == jour]
            if day_preds:
                day_accuracies = [p['accuracy'] for p in day_preds]
                stats['by_day'][jour] = {
                    'count': len(day_preds),
                    'avg_accuracy': np.mean(day_accuracies)
                }
        
        return stats
    
    def _get_recent_trend(self):
        """Analyse la tendance r√©cente"""
        if len(self.predictions_history) < 3:
            return "Historique insuffisant"
        
        recent_rates = [p['final_rework_rate'] for p in self.predictions_history[-5:]]
        
        if recent_rates[-1] > recent_rates[0] * 1.1:
            return "üìà Tendance √† la hausse"
        elif recent_rates[-1] < recent_rates[0] * 0.9:
            return "üìâ Tendance √† la baisse"
        else:
            return "üìä Tendance stable"
    
    def export_history_to_excel(self):
        """Exporte l'historique vers Excel"""
        if not self.predictions_history:
            return None
        
        data = []
        for pred in self.predictions_history:
            row = {
                'Timestamp': pred['timestamp'],
                'Jour': pred['jour'],
                'Jour_Nom': ['Lun', 'Mar', 'Mer', 'Jeu', 'Ven', 'Sam', 'Dim'][pred['jour']-1],
                'Volume': pred['volume'],
                'M√©thode': pred['method'],
                'Taux_ML_%': pred['ml_prediction']['taux_rework_chaine']['moyenne_ponderee'],
                'Taux_Ajust√©_%': pred['adjusted_prediction']['taux_rework_chaine']['moyenne_ponderee'],
                'Taux_Final_%': pred['final_rework_rate'],
                'Pr√©cision_%': pred.get('accuracy', ''),
                'A_D√©fauts_R√©els': 'Oui' if pred.get('actual_defects') else 'Non'
            }
            data.append(row)
        
        df = pd.DataFrame(data)
        
        output = BytesIO()
        with pd.ExcelWriter(output, engine='openpyxl') as writer:
            df.to_excel(writer, sheet_name='Historique_Predictions', index=False)
            
            # Feuille avec statistiques
            stats = self.get_historical_statistics()
            if stats:
                stats_data = [
                    ['M√©trique', 'Valeur'],
                    ['Total pr√©dictions', stats['total_predictions']],
                    ['Pr√©dictions valid√©es', stats['validated_predictions']],
                    ['Pr√©cision moyenne (%)', f"{stats.get('avg_accuracy', 0):.1f}"],
                    ['Pr√©cision min (%)', f"{stats.get('min_accuracy', 0):.1f}"],
                    ['Pr√©cision max (%)', f"{stats.get('max_accuracy', 0):.1f}"],
                    ['Tendance r√©cente', stats['recent_trend']]
                ]
                
                stats_df = pd.DataFrame(stats_data[1:], columns=stats_data[0])
                stats_df.to_excel(writer, sheet_name='Statistiques', index=False)
        
        return output.getvalue()
    
    # M√©thodes h√©rit√©es (simplifi√©es)
    def calculate_weighted_average(self, predictions_postes):
        """Calcule la moyenne pond√©r√©e"""
        if not predictions_postes:
            return 0
        
        if not self.poste_weights:
            return np.mean(list(predictions_postes.values()))
        
        weighted_sum = sum(pred * self.poste_weights.get(poste, 0) 
                          for poste, pred in predictions_postes.items())
        total_weight = sum(self.poste_weights.get(poste, 0) 
                          for poste in predictions_postes.keys())
        
        return weighted_sum / total_weight if total_weight > 0 else np.mean(list(predictions_postes.values()))

class StreamlitPlanningWithHistory:
    """Planification int√©gr√©e avec historique pour Streamlit"""
    
    def __init__(self, predictor):
        self.predictor = predictor
        self.model = None
        self.variables = {}
        self.results = {}
        self.parameters = {}
    
    def configure_with_history(self, S=3, T=3, **params):
        """Configure la planification avec donn√©es historiques"""
        
        # Obtenir le dernier taux pr√©dit
        if not self.predictor.predictions_history:
            raise ValueError("Aucun historique disponible!")
        
        latest_pred = self.predictor.predictions_history[-1]
        base_rate = latest_pred['final_rework_rate']
        
        # Calculer l'incertitude bas√©e sur l'historique
        uncertainty = self._calculate_uncertainty()
        
        # G√©n√©rer les sc√©narios
        scenario_rates = self._generate_scenarios(base_rate, uncertainty, S)
        
        # Configuration des param√®tres
        R = params.get('R', [f'REF_{i+1:02d}' for i in range(8)])
        EDI = params.get('EDI', [25, 40, 35, 30, 45, 28, 38, 42])
        EDI_dict = {R[i]: EDI[i] for i in range(len(R))}
        
        # Capacit√©s
        CAPchaine = {}
        mean_capacity = params.get('mean_capacity', 180)
        for s in range(S):
            for t in range(T):
                CAPchaine[(s, t)] = mean_capacity
        
        # Taux de d√©faut par sc√©nario
        taux_defaut = {}
        for s in range(S):
            for i in R:
                taux_defaut[(s, i)] = scenario_rates[s] / 100
        
        self.parameters = {
            'S': S, 'T': T, 'R': R, 'EDI': EDI_dict,
            'CAPchaine': CAPchaine, 'taux_defaut': taux_defaut,
            'alpha_rework': params.get('alpha_rework', 0.8),
            'beta': params.get('beta', 1.2),
            'm': params.get('m', 5),
            'penalite_penurie': params.get('penalite_penurie', 1000),
            'base_rate': base_rate,
            'uncertainty': uncertainty,
            'scenario_rates': scenario_rates
        }
        
        return True
    
    def _calculate_uncertainty(self):
        """Calcule l'incertitude bas√©e sur l'historique"""
        if len(self.predictor.predictions_history) < 3:
            return 0.15
        
        recent_rates = [p['final_rework_rate'] for p in self.predictor.predictions_history[-10:]]
        
        if len(recent_rates) < 2:
            return 0.15
        
        mean_rate = np.mean(recent_rates)
        std_rate = np.std(recent_rates)
        
        cv = std_rate / mean_rate if mean_rate > 0 else 0.15
        return max(0.05, min(0.3, cv))
    
    def _generate_scenarios(self, base_rate, uncertainty, S):
        """G√©n√®re les sc√©narios de taux de rework"""
        scenarios = []
        
        if S == 1:
            scenarios = [base_rate]
        elif S == 3:
            scenarios = [
                base_rate * (1 - uncertainty),  # Optimiste
                base_rate,                      # Moyen
                base_rate * (1 + uncertainty)   # Pessimiste
            ]
        else:
            for s in range(S):
                factor = 1 + uncertainty * (2 * s / (S - 1) - 1)
                scenarios.append(base_rate * factor)
        
        return [max(0.5, min(25, rate)) for rate in scenarios]
    
    def solve_optimization(self, time_limit=300):
        """R√©sout le probl√®me d'optimisation"""
        if not self.parameters:
            raise ValueError("Configurez d'abord la planification!")
        
        # Cr√©er le mod√®le
        self._create_model()
        
        try:
            solver = plp.PULP_CBC_CMD(timeLimit=time_limit, msg=0)
            self.model.solve(solver)
            
            if self.model.status == plp.LpStatusOptimal:
                self._extract_results()
                return True
            else:
                st.error(f"√âchec d'optimisation: {plp.LpStatus[self.model.status]}")
                return False
                
        except Exception as e:
            st.error(f"Erreur lors de la r√©solution: {e}")
            return False
    
    def _create_model(self):
        """Cr√©e le mod√®le d'optimisation"""
        params = self.parameters
        S, T, R = params['S'], params['T'], params['R']
        
        self.model = plp.LpProblem("Planning_With_History", plp.LpMinimize)
        
        # Variables
        self.variables['q'] = plp.LpVariable.dicts(
            "q", [(s, i, t) for s in range(S) for i in R for t in range(T)],
            lowBound=0, cat='Continuous'
        )
        
        self.variables['penurie'] = plp.LpVariable.dicts(
            "penurie", [(s, i) for s in range(S) for i in R],
            lowBound=0, cat='Continuous'
        )
        
        # Contraintes
        self._add_constraints()
        self._set_objective()
    
    def _add_constraints(self):
        """Ajoute les contraintes"""
        params = self.parameters
        S, T, R = params['S'], params['T'], params['R']
        q, penurie = self.variables['q'], self.variables['penurie']
        
        # Contraintes de demande
        for s in range(S):
            for i in R:
                prod_effective = plp.lpSum([
                    q[(s, i, t)] * (1 - params['taux_defaut'][(s, i)] + 
                                   params['alpha_rework'] * params['taux_defaut'][(s, i)])
                    for t in range(T)
                ])
                
                self.model += (
                    prod_effective + penurie[(s, i)] >= params['EDI'][i],
                    f"Demande_s{s}_i{i}"
                )
        
        # Contraintes de capacit√©
        for s in range(S):
            for t in range(T):
                cap_utilisee = plp.lpSum([
                    q[(s, i, t)] * (1 + params['beta'] * params['taux_defaut'][(s, i)])
                    for i in R
                ])
                
                self.model += (
                    cap_utilisee <= params['CAPchaine'][(s, t)],
                    f"Capacite_s{s}_t{t}"
                )
    
    def _set_objective(self):
        """D√©finit la fonction objectif"""
        params = self.parameters
        S, T, R = params['S'], params['T'], params['R']
        q, penurie = self.variables['q'], self.variables['penurie']
        
        cout_production = plp.lpSum([
            (1/S) * 20 * q[(s, i, t)]
            for s in range(S) for i in R for t in range(T)
        ])
        
        cout_penuries = plp.lpSum([
            (1/S) * params['penalite_penurie'] * penurie[(s, i)]
            for s in range(S) for i in R
        ])
        
        # Prime de risque bas√©e sur l'incertitude
        prime_risque = params['uncertainty'] * 50 * plp.lpSum([
            penurie[(s, i)] for s in range(S) for i in R
        ])
        
        self.model += cout_production + cout_penuries + prime_risque
    
    def _extract_results(self):
        """Extrait les r√©sultats"""
        params = self.parameters
        S, T, R = params['S'], params['T'], params['R']
        
        production_results = {}
        for s in range(S):
            for i in R:
                for t in range(T):
                    key = (s, i, t)
                    production_results[key] = self.variables['q'][key].value() or 0
        
        penuries_results = {}
        for s in range(S):
            for i in R:
                key = (s, i)
                penuries_results[key] = self.variables['penurie'][key].value() or 0
        
        self.results = {
            'production': production_results,
            'penuries': penuries_results,
            'cout_total': self.model.objective.value(),
            'historical_context': {
                'base_rate': params['base_rate'],
                'uncertainty': params['uncertainty'],
                'scenario_rates': params['scenario_rates']
            }
        }

# =====================================================================
# FONCTIONS DE VISUALISATION STREAMLIT
# =====================================================================

def create_history_trend_chart(predictions_history):
    """Cr√©e un graphique des tendances historiques"""
    if not predictions_history:
        return None
    
    # Pr√©parer les donn√©es
    data = []
    for pred in predictions_history:
        data.append({
            'Timestamp': pred['timestamp'],
            'Jour': ['Lun', 'Mar', 'Mer', 'Jeu', 'Ven', 'Sam', 'Dim'][pred['jour']-1],
            'Volume': pred['volume'],
            'Taux_ML': pred['ml_prediction']['taux_rework_chaine']['moyenne_ponderee'],
            'Taux_Ajust√©': pred['adjusted_prediction']['taux_rework_chaine']['moyenne_ponderee'],
            'Taux_Final': pred['final_rework_rate'],
            'Pr√©cision': pred.get('accuracy', None)
        })
    
    df = pd.DataFrame(data)
    
    # Graphique principal
    fig = make_subplots(
        rows=2, cols=1,
        subplot_titles=('√âvolution des Taux de Rework', 'Pr√©cision des Pr√©dictions'),
        vertical_spacing=0.1
    )
    
    # Taux de rework
    fig.add_trace(
        go.Scatter(x=df['Timestamp'], y=df['Taux_ML'], 
                  name='Pr√©diction ML', line=dict(color='blue'), mode='lines+markers'),
        row=1, col=1
    )
    
    fig.add_trace(
        go.Scatter(x=df['Timestamp'], y=df['Taux_Ajust√©'], 
                  name='Taux Ajust√©', line=dict(color='orange'), mode='lines+markers'),
        row=1, col=1
    )
    
    fig.add_trace(
        go.Scatter(x=df['Timestamp'], y=df['Taux_Final'], 
                  name='Taux Final', line=dict(color='red', width=3), mode='lines+markers'),
        row=1, col=1
    )
    
    # Pr√©cision (si disponible)
    precision_data = df[df['Pr√©cision'].notna()]
    if not precision_data.empty:
        fig.add_trace(
            go.Scatter(x=precision_data['Timestamp'], y=precision_data['Pr√©cision'],
                      name='Pr√©cision (%)', line=dict(color='green'), mode='lines+markers'),
            row=2, col=1
        )
    
    fig.update_layout(height=600, showlegend=True)
    fig.update_xaxes(title_text="Temps", row=2, col=1)
    fig.update_yaxes(title_text="Taux de Rework (%)", row=1, col=1)
    fig.update_yaxes(title_text="Pr√©cision (%)", row=2, col=1)
    
    return fig

def create_accuracy_by_day_chart(predictions_history):
    """Cr√©e un graphique de pr√©cision par jour"""
    if not predictions_history:
        return None
    
    # Grouper par jour
    day_data = {}
    for pred in predictions_history:
        if pred.get('accuracy') is not None:
            jour = pred['jour']
            if jour not in day_data:
                day_data[jour] = []
            day_data[jour].append(pred['accuracy'])
    
    if not day_data:
        return None
    
    # Calculer les moyennes
    days = []
    accuracies = []
    day_names = ['Lun', 'Mar', 'Mer', 'Jeu', 'Ven', 'Sam', 'Dim']
    
    for jour in range(1, 8):
        if jour in day_data:
            days.append(day_names[jour-1])
            accuracies.append(np.mean(day_data[jour]))
    
    fig = go.Figure(data=[
        go.Bar(x=days, y=accuracies, 
               marker_color=['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', 
                           '#9467bd', '#8c564b', '#e377c2'][:len(days)])
    ])
    
    fig.update_layout(
        title="Pr√©cision Moyenne par Jour de la Semaine",
        xaxis_title="Jour",
        yaxis_title="Pr√©cision (%)",
        yaxis=dict(range=[0, 100])
    )
    
    return fig

def create_planning_scenarios_chart(planning_results):
    """Cr√©e un graphique de comparaison des sc√©narios de planification"""
    if not planning_results or 'historical_context' not in planning_results:
        return None
    
    context = planning_results['historical_context']
    scenario_rates = context['scenario_rates']
    
    # Donn√©es pour le graphique
    scenario_names = []
    if len(scenario_rates) == 3:
        scenario_names = ['Optimiste', 'Moyen', 'Pessimiste']
    else:
        scenario_names = [f'Sc√©nario {i+1}' for i in range(len(scenario_rates))]
    
    fig = go.Figure(data=[
        go.Bar(x=scenario_names, y=scenario_rates,
               marker_color=['green', 'orange', 'red'][:len(scenario_rates)],
               text=[f'{rate:.2f}%' for rate in scenario_rates],
               textposition='auto')
    ])
    
    fig.update_layout(
        title="Sc√©narios de Taux de Rework pour la Planification",
        xaxis_title="Sc√©nario",
        yaxis_title="Taux de Rework (%)",
        showlegend=False
    )
    
    return fig

def create_demo_data_for_download():
    """Cr√©e des donn√©es de d√©monstration t√©l√©chargeables"""
    np.random.seed(42)
    data = []
    
    for day in range(1, 101):
        jour_semaine = ((day - 1) % 7) + 1
        
        if jour_semaine in [6, 7]:  # Weekend
            volume_base = 800
        else:
            volume_base = 1200
        
        volume = volume_base + np.random.normal(0, 100)
        volume = max(volume, 500)
        
        # Simulation de d√©fauts avec corr√©lation jour/volume
        poste1_defauts = volume * 0.02 + jour_semaine * 0.5 + np.random.normal(0, 2)
        poste2_defauts = volume * 0.015 + jour_semaine * 0.3 + np.random.normal(0, 1.5)
        poste3_defauts = volume * 0.025 + jour_semaine * 0.4 + np.random.normal(0, 2.5)
        
        data.append({
            'Jour': jour_semaine,
            'Volume_production': max(0, volume),
            'Poste1_defauts': max(0, poste1_defauts),
            'Poste2_defauts': max(0, poste2_defauts),
            'Poste3_defauts': max(0, poste3_defauts)
        })
    
    return pd.DataFrame(data)

# =====================================================================
# INTERFACE STREAMLIT PRINCIPALE
# =====================================================================

def main():
    # En-t√™te principal
    st.markdown("""
    <div class="main-header">
        <h1>üè≠ Syst√®me Int√©gr√© avec Historique Intelligent</h1>
        <p>Pr√©diction adaptative + Planification bas√©e sur l'historique + Apprentissage continu</p>
    </div>
    """, unsafe_allow_html=True)

    # Initialisation des variables de session
    if 'enhanced_predictor' not in st.session_state:
        st.session_state.enhanced_predictor = EnhancedStreamlitDefectPredictor()
        st.session_state.system_configured = False
        st.session_state.planning_configured = False
        st.session_state.planner = None

    # Sidebar pour navigation
    st.sidebar.title("üß≠ Navigation")
    page = st.sidebar.selectbox(
        "Choisissez une section:",
        [
            "üè† Accueil",
            "üìä Configuration Syst√®me", 
            "üìù Nouvelle Demande",
            "üìà Historique & Tendances",
            "üéØ Planification Intelligente",
            "üìã R√©sultats Int√©gr√©s",
            "üíæ Export & Statistiques"
        ]
    )

    # =================== PAGE ACCUEIL ===================
    if page == "üè† Accueil":
        st.header("Bienvenue dans le Syst√®me Am√©lior√©")
        
        st.markdown("""
        ### üéØ Nouvelles Fonctionnalit√©s
        
        **üß† Apprentissage Continu:**
        - Historique complet des pr√©dictions
        - Ajustement automatique bas√© sur les erreurs pass√©es
        - Am√©lioration de la pr√©cision au fil du temps
        
        **üìä Analyse Avanc√©e:**
        - Tendances par jour de la semaine
        - Statistiques de performance
        - Facteurs de correction intelligents
        
        **üéØ Planification Robuste:**
        - Sc√©narios bas√©s sur l'incertitude historique
        - Gestion du risque adaptive
        - Optimisation avec contexte
        """)
        
        # Statut du syst√®me
        st.markdown("### üìã Statut Actuel")
        
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            if st.session_state.system_configured:
                st.success("‚úÖ Syst√®me Configur√©")
            else:
                st.warning("‚è≥ √Ä Configurer")
        
        with col2:
            hist_count = len(st.session_state.enhanced_predictor.predictions_history)
            if hist_count > 0:
                st.info(f"üìä {hist_count} Pr√©dictions")
            else:
                st.warning("üì≠ Aucun Historique")
        
        with col3:
            if st.session_state.planning_configured:
                st.success("‚úÖ Planning Configur√©")
            else:
                st.warning("‚è≥ Planning √Ä Faire")
        
        with col4:
            stats = st.session_state.enhanced_predictor.get_historical_statistics()
            if stats and 'avg_accuracy' in stats:
                st.metric("üéØ Pr√©cision Moy.", f"{stats['avg_accuracy']:.1f}%")
            else:
                st.warning("‚è≥ Pas de Validation")
        
        # Tendance r√©cente
        if stats:
            st.markdown("### üìà Tendance R√©cente")
            st.info(stats['recent_trend'])

    # =================== CONFIGURATION SYST√àME ===================
    elif page == "üìä Configuration Syst√®me":
        st.header("üìä Configuration du Syst√®me")
        
        st.markdown("### üîß √âtape 1: Source des Donn√©es")
        
        data_source = st.radio(
            "Choisissez la source:",
            ["üí° Donn√©es de d√©monstration", "üìÅ Fichier Excel"]
        )
        
        if data_source == "üí° Donn√©es de d√©monstration":
            n_days = st.slider("Nombre de jours √† g√©n√©rer:", 50, 200, 100)
            
            if st.button("üöÄ Configurer avec Donn√©es Demo"):
                with st.spinner("Configuration en cours..."):
                    try:
                        # Cr√©er les donn√©es de d√©mo
                        demo_data = create_demo_data_for_download()
                        
                        # Simuler la configuration du syst√®me
                        predictor = st.session_state.enhanced_predictor
                        predictor.postes = ['Poste1_defauts', 'Poste2_defauts', 'Poste3_defauts']
                        predictor.jour_col = 'Jour'
                        predictor.volume_col = 'Volume_production'
                        predictor.poste_weights = {
                            'Poste1_defauts': 0.4, 
                            'Poste2_defauts': 0.35, 
                            'Poste3_defauts': 0.25
                        }
                        
                        # Simuler des mod√®les entra√Æn√©s
                        class DummyModel:
                            def __init__(self, base_rate):
                                self.base_rate = base_rate
                            
                            def predict(self, X):
                                volume = X.iloc[0, 0] if hasattr(X, 'iloc') else X[0][0]
                                jour = X.iloc[0, 1] if hasattr(X, 'iloc') else X[0][1]
                                
                                base_defects = volume * self.base_rate
                                jour_factor = 1.0 + (jour - 4) * 0.02
                                noise = np.random.normal(0, volume * 0.005)
                                
                                return [max(0, base_defects * jour_factor + noise)]
                        
                        predictor.models = {
                            'Poste1_defauts': DummyModel(0.020),
                            'Poste2_defauts': DummyModel(0.015),
                            'Poste3_defauts': DummyModel(0.025)
                        }
                        
                        st.session_state.system_configured = True
                        st.success("‚úÖ Syst√®me configur√© avec succ√®s!")
                        
                        # Afficher les informations
                        st.markdown("### üß† Mod√®les Simul√©s")
                        model_info = {
                            'Poste': ['Poste1_defauts', 'Poste2_defauts', 'Poste3_defauts'],
                            'Taux Base (%)': ['2.0%', '1.5%', '2.5%'],
                            'Poids': ['40%', '35%', '25%'],
                            'Statut': ['‚úÖ Actif', '‚úÖ Actif', '‚úÖ Actif']
                        }
                        st.dataframe(pd.DataFrame(model_info))
                        
                    except Exception as e:
                        st.error(f"‚ùå Erreur: {e}")
        
        else:  # Fichier Excel
            uploaded_file = st.file_uploader(
                "T√©l√©chargez votre fichier Excel",
                type=['xlsx', 'xls'],
                help="Colonnes requises: Jour, Volume_production, et colonnes de d√©fauts"
            )
            
            if uploaded_file is not None:
                try:
                    data = pd.read_excel(uploaded_file)
                    st.write("**Aper√ßu des donn√©es:**")
                    st.dataframe(data.head())
                    
                    if st.button("üöÄ Configurer avec Fichier"):
                        # Ici vous pourriez ajouter la logique d'entra√Ænement r√©elle
                        st.warning("‚ö†Ô∏è Entra√Ænement r√©el des mod√®les non impl√©ment√© dans cette d√©mo")
                        
                except Exception as e:
                    st.error(f"‚ùå Erreur lecture fichier: {e}")
        
        # Bouton pour t√©l√©charger les donn√©es de d√©mo
        st.markdown("### üíæ T√©l√©charger Donn√©es de D√©monstration")
        if st.button("üì• G√©n√©rer Fichier Excel Demo"):
            demo_data = create_demo_data_for_download()
            
            output = BytesIO()
            with pd.ExcelWriter(output, engine='openpyxl') as writer:
                demo_data.to_excel(writer, sheet_name='Donn√©es_Demo', index=False)
            
            st.download_button(
                label="üíæ T√©l√©charger donn√©es_demo.xlsx",
                data=output.getvalue(),
                file_name="donnees_demo.xlsx",
                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
            )

    # =================== NOUVELLE DEMANDE ===================
    elif page == "üìù Nouvelle Demande":
        st.header("üìù Nouvelle Demande de Pr√©diction")
        
        if not st.session_state.system_configured:
            st.warning("‚ö†Ô∏è Veuillez d'abord configurer le syst√®me.")
            return
        
        st.markdown("### üìã Param√®tres de la Nouvelle Demande")
        
        col1, col2 = st.columns(2)
        
        with col1:
            jour = st.selectbox(
                "Jour de la semaine:",
                options=list(range(1, 8)),
                format_func=lambda x: ['Lundi', 'Mardi', 'Mercredi', 'Jeudi', 'Vendredi', 'Samedi', 'Dimanche'][x-1]
            )
        
        with col2:
            volume = st.number_input(
                "Volume de production pr√©vu:",
                min_value=100,
                max_value=3000,
                value=1200,
                step=50
            )
        
        method = st.selectbox(
            "M√©thode de calcul:",
            options=['moyenne_ponderee', 'moyenne', 'max', 'somme'],
            format_func=lambda x: {
                'moyenne_ponderee': '‚öñÔ∏è Moyenne Pond√©r√©e (Recommand√©)',
                'moyenne': 'üìä Moyenne Simple',
                'max': 'üî∫ Maximum',
                'somme': '‚ûï Somme'
            }[x]
        )
        
        # Option pour ajouter les d√©fauts r√©els
        with_validation = st.checkbox("üîç J'ai les d√©fauts r√©els pour validation")
        
        actual_defects = None
        if with_validation:
            st.markdown("### üìä D√©fauts R√©els (pour validation)")
            col1, col2, col3 = st.columns(3)
            
            with col1:
                poste1_real = st.number_input("D√©fauts Poste1:", min_value=0.0, value=0.0, step=0.1)
            with col2:
                poste2_real = st.number_input("D√©fauts Poste2:", min_value=0.0, value=0.0, step=0.1)
            with col3:
                poste3_real = st.number_input("D√©fauts Poste3:", min_value=0.0, value=0.0, step=0.1)
            
            actual_defects = {
                'Poste1_defauts': poste1_real,
                'Poste2_defauts': poste2_real,
                'Poste3_defauts': poste3_real
            }
        
        if st.button("üîÆ Faire la Pr√©diction", type="primary"):
            with st.spinner("Pr√©diction en cours..."):
                try:
                    # Faire la pr√©diction avec historique
                    result = st.session_state.enhanced_predictor.add_new_demand_prediction(
                        jour=jour,
                        volume=volume,
                        actual_defects=actual_defects,
                        method=method
                    )
                    
                    # Afficher les r√©sultats
                    st.markdown("### üéØ R√©sultats de la Pr√©diction")
                    
                    # M√©triques principales
                    col1, col2, col3, col4 = st.columns(4)
                    
                    with col1:
                        st.metric(
                            "üéØ Taux Final",
                            f"{result['final_rework_rate']:.2f}%"
                        )
                    
                    with col2:
                        ml_rate = result['ml_prediction']['taux_rework_chaine'][method]
                        st.metric(
                            "ü§ñ Pr√©diction ML",
                            f"{ml_rate:.2f}%"
                        )
                    
                    with col3:
                        adj_rate = result['adjusted_prediction']['taux_rework_chaine'][method]
                        st.metric(
                            "üîß Taux Ajust√©",
                            f"{adj_rate:.2f}%"
                        )
                    
                    with col4:
                        if result.get('accuracy') is not None:
                            st.metric(
                                "üìä Pr√©cision",
                                f"{result['accuracy']:.1f}%"
                            )
                        else:
                            st.metric("üìä Pr√©cision", "N/A")
                    
                    # D√©tails par poste
                    st.markdown("### üè≠ D√©tails par Poste")
                    
                    poste_data = []
                    for poste, defauts in result['ml_prediction']['predictions_postes'].items():
                        taux = result['ml_prediction']['taux_rework_postes'][poste]
                        real_defects = actual_defects.get(poste, "N/A") if actual_defects else "N/A"
                        
                        poste_data.append({
                            'Poste': poste,
                            'D√©fauts Pr√©dits': f"{defauts:.1f}",
                            'Taux Rework (%)': f"{taux:.2f}",
                            'D√©fauts R√©els': real_defects,
                            'Poids': f"{st.session_state.enhanced_predictor.poste_weights.get(poste, 0):.1%}"
                        })
                    
                    st.dataframe(pd.DataFrame(poste_data), use_container_width=True)
                    
                    # Facteur de correction appliqu√©
                    ml_final_diff = result['final_rework_rate'] - result['ml_prediction']['taux_rework_chaine'][method]
                    if abs(ml_final_diff) > 0.1:
                        correction_info = "üìà Correction √† la hausse" if ml_final_diff > 0 else "üìâ Correction √† la baisse"
                        st.info(f"{correction_info} appliqu√©e: {ml_final_diff:+.2f}%")
                    
                    # Message de succ√®s
                    st.success("‚úÖ Pr√©diction ajout√©e √† l'historique avec succ√®s!")
                    
                except Exception as e:
                    st.error(f"‚ùå Erreur lors de la pr√©diction: {e}")

    # =================== HISTORIQUE & TENDANCES ===================
    elif page == "üìà Historique & Tendances":
        st.header("üìà Historique et Analyse des Tendances")
        
        predictor = st.session_state.enhanced_predictor
        history = predictor.predictions_history
        
        if not history:
            st.info("üì≠ Aucun historique disponible. Ajoutez des pr√©dictions d'abord.")
            return
        
        # Statistiques g√©n√©rales
        stats = predictor.get_historical_statistics()
        
        st.markdown("### üìä Statistiques G√©n√©rales")
        
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            st.metric("Total Pr√©dictions", stats['total_predictions'])
        
        with col2:
            st.metric("Avec Validation", stats['validated_predictions'])
        
        with col3:
            if 'avg_accuracy' in stats:
                st.metric("Pr√©cision Moyenne", f"{stats['avg_accuracy']:.1f}%")
            else:
                st.metric("Pr√©cision Moyenne", "N/A")
        
        with col4:
            st.metric("Tendance", stats['recent_trend'].replace('üìà', '').replace('üìâ', '').replace('üìä', '').strip())
        
        # Graphique des tendances
        st.markdown("### üìà √âvolution des Pr√©dictions")
        
        trend_chart = create_history_trend_chart(history)
        if trend_chart:
            st.plotly_chart(trend_chart, use_container_width=True)
        
        # Pr√©cision par jour
        if stats['validated_predictions'] > 0:
            st.markdown("### üìä Performance par Jour de la Semaine")
            
            accuracy_chart = create_accuracy_by_day_chart(history)
            if accuracy_chart:
                st.plotly_chart(accuracy_chart, use_container_width=True)
        
        # Tableau d√©taill√© de l'historique
        st.markdown("### üìã Historique D√©taill√©")
        
        n_display = st.slider("Nombre d'entr√©es √† afficher:", 5, min(50, len(history)), 10)
        
        recent_history = history[-n_display:]
        
        display_data = []
        for i, pred in enumerate(reversed(recent_history), 1):
            day_name = ['Lun', 'Mar', 'Mer', 'Jeu', 'Ven', 'Sam', 'Dim'][pred['jour']-1]
            
            display_data.append({
                '#': len(history) - i + 1,
                'Date/Heure': pred['timestamp'].strftime("%Y-%m-%d %H:%M"),
                'Jour': day_name,
                'Volume': f"{pred['volume']:,}",
                'Taux Final (%)': f"{pred['final_rework_rate']:.2f}",
                'Pr√©cision (%)': f"{pred['accuracy']:.1f}" if pred.get('accuracy') else "N/A",
                'Valid√©': "‚úÖ" if pred.get('actual_defects') else "‚ùå"
            })
        
        st.dataframe(pd.DataFrame(display_data), use_container_width=True)

    # =================== PLANIFICATION INTELLIGENTE ===================
    elif page == "üéØ Planification Intelligente":
        st.header("üéØ Planification Intelligente avec Historique")
        
        predictor = st.session_state.enhanced_predictor
        
        if not predictor.predictions_history:
            st.warning("‚ö†Ô∏è Aucune pr√©diction disponible. Ajoutez d'abord une demande.")
            return
        
        st.markdown("### üìã Configuration de la Planification")
        
        col1, col2 = st.columns(2)
        
        with col1:
            S = st.number_input("Nombre de sc√©narios:", min_value=1, max_value=5, value=3)
            T = st.number_input("Nombre de shifts:", min_value=1, max_value=5, value=3)
        
        with col2:
            mean_capacity = st.number_input("Capacit√© par shift:", min_value=100, max_value=500, value=180)
            penalite_penurie = st.number_input("P√©nalit√© p√©nurie:", min_value=500, max_value=2000, value=1000)
        
        # Informations sur la derni√®re pr√©diction
        latest_pred = predictor.predictions_history[-1]
        
        st.markdown("### üîÆ Contexte de la Derni√®re Pr√©diction")
        
        col1, col2, col3 = st.columns(3)
        
        with col1:
            st.metric("Jour", ['Lun', 'Mar', 'Mer', 'Jeu', 'Ven', 'Sam', 'Dim'][latest_pred['jour']-1])
        
        with col2:
            st.metric("Volume", f"{latest_pred['volume']:,}")
        
        with col3:
            st.metric("Taux Final", f"{latest_pred['final_rework_rate']:.2f}%")
        
        if st.button("üöÄ Configurer et Optimiser", type="primary"):
            with st.spinner("Configuration et optimisation en cours..."):
                try:
                    # Cr√©er le planificateur
                    planner = StreamlitPlanningWithHistory(predictor)
                    
                    # Configurer avec l'historique
                    success = planner.configure_with_history(
                        S=S, T=T,
                        mean_capacity=mean_capacity,
                        penalite_penurie=penalite_penurie,
                        alpha_rework=0.8,
                        beta=1.2,
                        m=5
                    )
                    
                    if not success:
                        st.error("‚ùå √âchec de la configuration")
                        return
                    
                    # R√©soudre l'optimisation
                    success = planner.solve_optimization(time_limit=300)
                    
                    if success:
                        st.session_state.planner = planner
                        st.session_state.planning_configured = True
                        st.success("‚úÖ Optimisation r√©ussie!")
                        
                        # Afficher les r√©sultats
                        st.markdown("### üìä R√©sultats de l'Optimisation")
                        
                        results = planner.results
                        context = results['historical_context']
                        
                        # M√©triques principales
                        col1, col2, col3, col4 = st.columns(4)
                        
                        with col1:
                            st.metric("Co√ªt Total", f"{results['cout_total']:.0f}")
                        
                        with col2:
                            st.metric("Taux Base", f"{context['base_rate']:.2f}%")
                        
                        with col3:
                            st.metric("Incertitude", f"{context['uncertainty']:.1%}")
                        
                        with col4:
                            st.metric("Sc√©narios", len(context['scenario_rates']))
                        
                        # Graphique des sc√©narios
                        st.markdown("### üìà Sc√©narios Consid√©r√©s")
                        
                        scenario_chart = create_planning_scenarios_chart(results)
                        if scenario_chart:
                            st.plotly_chart(scenario_chart, use_container_width=True)
                        
                        # D√©tails des sc√©narios
                        st.markdown("### üìã D√©tails des Sc√©narios")
                        
                        scenario_data = []
                        scenario_names = ['Optimiste', 'Moyen', 'Pessimiste'] if S == 3 else [f'Sc√©nario {i+1}' for i in range(S)]
                        
                        for i, (name, rate) in enumerate(zip(scenario_names, context['scenario_rates'])):
                            scenario_data.append({
                                'Sc√©nario': name,
                                'Taux Rework (%)': f"{rate:.2f}",
                                'Probabilit√©': f"{100/S:.1f}%",
                                'Type': 'Historique + Incertitude'
                            })
                        
                        st.dataframe(pd.DataFrame(scenario_data), use_container_width=True)
                        
                    else:
                        st.error("‚ùå √âchec de l'optimisation")
                        
                except Exception as e:
                    st.error(f"‚ùå Erreur: {e}")

    # =================== R√âSULTATS INT√âGR√âS ===================
    elif page == "üìã R√©sultats Int√©gr√©s":
        st.header("üìã R√©sultats du Syst√®me Int√©gr√©")
        
        if not st.session_state.planning_configured or not st.session_state.planner:
            st.warning("‚ö†Ô∏è Effectuez d'abord une planification.")
            return
        
        planner = st.session_state.planner
        predictor = st.session_state.enhanced_predictor
        
        # R√©sum√© ex√©cutif
        st.markdown("### üìä R√©sum√© Ex√©cutif")
        
        results = planner.results
        context = results['historical_context']
        stats = predictor.get_historical_statistics()
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown("""
            **üîÆ Pr√©diction:**
            - Historique: {} pr√©dictions
            - Pr√©cision moyenne: {:.1f}%
            - Tendance: {}
            """.format(
                stats['total_predictions'],
                stats.get('avg_accuracy', 0),
                stats['recent_trend']
            ))
        
        with col2:
            st.markdown("""
            **üìã Planification:**
            - Co√ªt optimal: {:.0f}
            - Incertitude: {:.1%}
            - Sc√©narios: {}
            """.format(
                results['cout_total'],
                context['uncertainty'],
                len(context['scenario_rates'])
            ))
        
        # Analyse de robustesse
        st.markdown("### üõ°Ô∏è Analyse de Robustesse")
        
        if context['uncertainty'] < 0.10:
            robustesse = "üü¢ Forte - Historique stable"
        elif context['uncertainty'] < 0.20:
            robustesse = "üü° Mod√©r√©e - Variabilit√© contr√¥l√©e"
        else:
            robustesse = "üî¥ Faible - Forte incertitude"
        
        st.info(f"**Niveau de robustesse:** {robustesse}")
        
        # Recommandations
        st.markdown("### üí° Recommandations")
        
        recommendations = []
        
        if stats['validated_predictions'] < 5:
            recommendations.append("üìä Collecter plus de validations pour am√©liorer la pr√©cision")
        
        if context['uncertainty'] > 0.15:
            recommendations.append("‚öñÔ∏è Consid√©rer des marges de s√©curit√© plus importantes")
        
        if stats.get('avg_accuracy', 0) < 80:
            recommendations.append("üîß R√©viser les param√®tres des mod√®les de pr√©diction")
        
        if 'üìà' in stats['recent_trend']:
            recommendations.append("üìà Surveiller la tendance haussi√®re des d√©fauts")
        
        if not recommendations:
            recommendations.append("‚úÖ Syst√®me performant - Continuer le monitoring")
        
        for rec in recommendations:
            st.write(f"‚Ä¢ {rec}")

    # =================== EXPORT & STATISTIQUES ===================
    elif page == "üíæ Export & Statistiques":
        st.header("üíæ Export et Statistiques Avanc√©es")
        
        predictor = st.session_state.enhanced_predictor
        
        if not predictor.predictions_history:
            st.info("üì≠ Aucun historique √† exporter.")
            return
        
        # Statistiques d√©taill√©es
        st.markdown("### üìä Statistiques D√©taill√©es")
        
        stats = predictor.get_historical_statistics()
        
        # Tableau de statistiques
        if stats:
            stats_display = [
                ["üìà Total Pr√©dictions", stats['total_predictions']],
                ["‚úÖ Pr√©dictions Valid√©es", stats['validated_predictions']],
                ["üéØ Pr√©cision Moyenne", f"{stats.get('avg_accuracy', 0):.1f}%"],
                ["üìä Pr√©cision Min/Max", f"{stats.get('min_accuracy', 0):.1f}% / {stats.get('max_accuracy', 0):.1f}%"],
                ["üìà Tendance R√©cente", stats['recent_trend']],
                ["üìè √âcart-Type Pr√©cision", f"{stats.get('std_accuracy', 0):.1f}%"]
            ]
            
            stats_df = pd.DataFrame(stats_display, columns=['M√©trique', 'Valeur'])
            st.dataframe(stats_df, use_container_width=True)
        
        # Statistiques par jour
        if 'by_day' in stats and stats['by_day']:
            st.markdown("### üìÖ Performance par Jour de la Semaine")
            
            day_names = ['Lundi', 'Mardi', 'Mercredi', 'Jeudi', 'Vendredi', 'Samedi', 'Dimanche']
            day_stats = []
            
            for jour in range(1, 8):
                if jour in stats['by_day']:
                    day_data = stats['by_day'][jour]
                    day_stats.append({
                        'Jour': day_names[jour-1],
                        'Nombre': day_data['count'],
                        'Pr√©cision Moyenne (%)': f"{day_data['avg_accuracy']:.1f}"
                    })
                else:
                    day_stats.append({
                        'Jour': day_names[jour-1],
                        'Nombre': 0,
                        'Pr√©cision Moyenne (%)': 'N/A'
                    })
            
            st.dataframe(pd.DataFrame(day_stats), use_container_width=True)
        
        # Export des donn√©es
        st.markdown("### üíæ Export des Donn√©es")
        
        col1, col2 = st.columns(2)
        
        with col1:
            if st.button("üì• Exporter Historique Excel"):
                excel_data = predictor.export_history_to_excel()
                if excel_data:
                    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                    filename = f"historique_predictions_{timestamp}.xlsx"
                    
                    st.download_button(
                        label="üíæ T√©l√©charger Excel",
                        data=excel_data,
                        file_name=filename,
                        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                    )
                    
                    st.success("‚úÖ Fichier Excel g√©n√©r√©!")
                else:
                    st.error("‚ùå Erreur lors de la g√©n√©ration")
        
        with col2:
            if st.button("üìä Exporter Rapport CSV"):
                # Cr√©er un CSV simplifi√©
                csv_data = []
                for pred in predictor.predictions_history:
                    csv_data.append({
                        'Timestamp': pred['timestamp'].strftime("%Y-%m-%d %H:%M:%S"),
                        'Jour': pred['jour'],
                        'Volume': pred['volume'],
                        'Taux_Final_%': pred['final_rework_rate'],
                        'Pr√©cision_%': pred.get('accuracy', ''),
                        'Valid√©': pred.get('actual_defects') is not None
                    })
                
                csv_df = pd.DataFrame(csv_data)
                csv_string = csv_df.to_csv(index=False)
                
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                filename = f"rapport_predictions_{timestamp}.csv"
                
                st.download_button(
                    label="üíæ T√©l√©charger CSV",
                    data=csv_string,
                    file_name=filename,
                    mime="text/csv"
                )
        
        # Nettoyage de l'historique
        st.markdown("### üßπ Gestion de l'Historique")
        
        st.warning("‚ö†Ô∏è Actions de nettoyage - Utilisez avec pr√©caution")
        
        col1, col2 = st.columns(2)
        
        with col1:
            if st.button("üóëÔ∏è Supprimer Derni√®re Pr√©diction"):
                if predictor.predictions_history:
                    removed = predictor.predictions_history.pop()
                    predictor.save_history()
                    st.success(f"‚úÖ Pr√©diction du {removed['timestamp'].strftime('%Y-%m-%d %H:%M')} supprim√©e")
                    st.experimental_rerun()
                else:
                    st.error("‚ùå Aucune pr√©diction √† supprimer")
        
        with col2:
            if st.button("üßπ Vider Tout l'Historique"):
                if st.session_state.get('confirm_clear', False):
                    predictor.predictions_history = []
                    predictor.save_history()
                    st.session_state.confirm_clear = False
                    st.success("‚úÖ Historique compl√®tement vid√©")
                    st.experimental_rerun()
                else:
                    st.session_state.confirm_clear = True
                    st.error("‚ö†Ô∏è Cliquez √† nouveau pour confirmer la suppression")

# =====================================================================
# FONCTIONS UTILITAIRES SUPPL√âMENTAIRES
# =====================================================================

def create_system_summary():
    """Cr√©e un r√©sum√© du syst√®me pour la sidebar"""
    if 'enhanced_predictor' in st.session_state:
        predictor = st.session_state.enhanced_predictor
        history_count = len(predictor.predictions_history)
        
        if history_count > 0:
            stats = predictor.get_historical_statistics()
            
            st.sidebar.markdown("### üìä R√©sum√© Syst√®me")
            st.sidebar.metric("Historique", f"{history_count} pr√©dictions")
            
            if 'avg_accuracy' in stats:
                st.sidebar.metric("Pr√©cision Moy.", f"{stats['avg_accuracy']:.1f}%")
            
            st.sidebar.write(f"**Tendance:** {stats['recent_trend']}")

def initialize_demo_history():
    """Initialise un historique de d√©monstration"""
    if st.sidebar.button("üé≤ Cr√©er Historique Demo"):
        if 'enhanced_predictor' in st.session_state:
            predictor = st.session_state.enhanced_predictor
            
            # Vider l'historique existant
            predictor.predictions_history = []
            
            # Cr√©er quelques pr√©dictions de d√©monstration
            demo_predictions = [
                (2, 1100, {'Poste1_defauts': 22, 'Poste2_defauts': 16, 'Poste3_defauts': 28}),
                (3, 1250, {'Poste1_defauts': 25, 'Poste2_defauts': 19, 'Poste3_defauts': 31}),
                (4, 1180, None),
                (5, 1350, {'Poste1_defauts': 27, 'Poste2_defauts': 20, 'Poste3_defauts': 34}),
                (1, 950, {'Poste1_defauts': 19, 'Poste2_defauts': 14, 'Poste3_defauts': 24}),
            ]
            
            for jour, volume, actual in demo_predictions:
                predictor.add_new_demand_prediction(jour, volume, actual)
            
            st.sidebar.success("‚úÖ Historique demo cr√©√©!")
            st.experimental_rerun()

# =====================================================================
# SIDEBAR AVEC INFORMATIONS
# =====================================================================

def create_sidebar_info():
    """Cr√©e les informations dans la sidebar"""
    st.sidebar.markdown("---")
    
    # R√©sum√© du syst√®me
    create_system_summary()
    
    st.sidebar.markdown("---")
    
    # Actions rapides
    st.sidebar.markdown("### ‚ö° Actions Rapides")
    
    # Bouton pour cr√©er un historique de d√©mo
    initialize_demo_history()
    
    # Informations sur la version
    st.sidebar.markdown("---")
    st.sidebar.markdown("### ‚ÑπÔ∏è Informations")
    st.sidebar.info("""
    **Version:** 2.0 Enhanced
    
    **Nouvelles fonctionnalit√©s:**
    - üß† Apprentissage continu
    - üìä Historique intelligent
    - üîß Ajustements automatiques
    - üìà Analyse de tendances
    - üõ°Ô∏è Planification robuste
    """)
    
    # Contact/aide
    st.sidebar.markdown("### üìû Support")
    st.sidebar.markdown("""
    Pour toute question:
    - üìß [support@syst√®me.com](mailto:support@syst√®me.com)
    - üìñ [Documentation](https://docs.syst√®me.com)
    - üêõ [Signaler un bug](https://github.com/syst√®me/issues)
    """)

# =====================================================================
# POINT D'ENTR√âE PRINCIPAL
# =====================================================================

if __name__ == "__main__":
    # Ajouter les informations de la sidebar
    create_sidebar_info()
    
    # Lancer l'application principale
    main()

# =====================================================================
# INSTRUCTIONS D'UTILISATION
# =====================================================================

"""
üöÄ INSTRUCTIONS D'UTILISATION:

1. **Installation:**
   pip install streamlit pandas numpy plotly scikit-learn pulp openpyxl

2. **Lancement:**
   streamlit run nom_du_fichier.py

3. **Workflow Recommand√©:**
   - Commencer par "Configuration Syst√®me"
   - Ajouter des "Nouvelles Demandes" avec validation
   - Analyser l'"Historique & Tendances"
   - Configurer la "Planification Intelligente"
   - Consulter les "R√©sultats Int√©gr√©s"
   - Exporter via "Export & Statistiques"

4. **Fonctionnalit√©s Cl√©s:**
   - ‚úÖ Interface web Streamlit conserv√©e
   - ‚úÖ Historique complet des pr√©dictions
   - ‚úÖ Ajustements automatiques bas√©s sur l'historique
   - ‚úÖ Validation avec d√©fauts r√©els
   - ‚úÖ Planification avec sc√©narios intelligents
   - ‚úÖ Visualisations interactives
   - ‚úÖ Export Excel/CSV
   - ‚úÖ Statistiques de performance

5. **Donn√©es de D√©monstration:**
   - Utilisez le bouton "Cr√©er Historique Demo" dans la sidebar
   - Ou configurez avec vos propres donn√©es Excel

6. **Am√©lioration Continue:**
   - Plus vous validez les pr√©dictions, plus le syst√®me s'am√©liore
   - L'historique permet des corrections automatiques
   - Les tendances sont analys√©es pour optimiser les futures pr√©dictions
"""
